{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the imports you will need in the whole lab\n",
    "from skimage import io\n",
    "from skimage.filters import median, gaussian\n",
    "import skimage.exposure as exposure\n",
    "from scipy.signal import convolve2d\n",
    "from skimage.morphology import binary_erosion, binary_dilation, binary_closing, skeletonize, thin\n",
    "from skimage.color import rgb2gray, rgb2hsv, rgb2yuv, rgb2ycbcr\n",
    "from skimage.measure import find_contours\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from skimage.feature import hog as hog_sk\n",
    "import os\n",
    "import numpy as np\n",
    "from commonfunctions import *\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "from skimage.util import img_as_float\n",
    "from scipy.spatial.distance import squareform, pdist, cdist\n",
    "from skimage.draw import polygon\n",
    "from sklearn import svm\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skin_mask_rgb(img):\n",
    "    red_channel = img[:,:,0]\n",
    "    green_channel = img[:,:,1]\n",
    "    blue_channel = img[:,:,2]\n",
    "    rgb_max = np.maximum(np.maximum(red_channel, green_channel), blue_channel)\n",
    "    rgb_min = np.minimum(np.minimum(red_channel, green_channel), blue_channel)\n",
    "    rgb_rule_1 = np.logical_and.reduce([\n",
    "        red_channel > 95, green_channel > 60, blue_channel > 60,\n",
    "        rgb_max - rgb_min > 15, abs(red_channel - green_channel) < 80, abs(red_channel - blue_channel) < 80,red_channel > green_channel, red_channel > blue_channel\n",
    "    ])\n",
    "    \n",
    "    rgb_rule_2 = np.logical_and.reduce([\n",
    "        red_channel > 220 , green_channel > 210 , blue_channel > 170,\n",
    "        abs(red_channel - green_channel) > 15, red_channel > blue_channel, green_channel > blue_channel\n",
    "    ])\n",
    "    return np.logical_or(rgb_rule_1, rgb_rule_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_thresholding(img):\n",
    "    hist = exposure.histogram(img, nbins=256)\n",
    "    total_num_of_pixels = img.shape[0]*img.shape[1]\n",
    "    initial_threshold = round(sum(hist[1]*hist[0])/total_num_of_pixels)\n",
    "    grey_level_count = hist[1][-1]\n",
    "    while True:\n",
    "        list_of_lower_values = hist[1][hist[1] < initial_threshold]\n",
    "        frequency_of_lower_values = hist[0][hist[1] < initial_threshold]\n",
    "        lower_threshold = round(sum(list_of_lower_values*frequency_of_lower_values)/sum(frequency_of_lower_values))\n",
    "\n",
    "        list_of_higher_values = hist[1][hist[1] >= initial_threshold]\n",
    "        frequency_of_higher_values = hist[0][hist[1] >= initial_threshold]\n",
    "        upper_threshold = round(sum(list_of_higher_values*frequency_of_higher_values)/sum(frequency_of_higher_values))\n",
    "        new_threshold = round((lower_threshold + upper_threshold)/2)\n",
    "        \n",
    "        if new_threshold == initial_threshold:\n",
    "            break\n",
    "        else:\n",
    "            initial_threshold = new_threshold\n",
    "    return new_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hand_contours(hand_img):\n",
    "    #get the center of the hand\n",
    "    hand_img = hand_img.astype(np.uint8)\n",
    "    contours = find_contours(hand_img, 0.8, fully_connected='high')\n",
    "    contouring_threshold = 0\n",
    "    # get contoring threshold by finding the min length of the longest 3 contours\n",
    "    contouring_threshold = sorted([c.shape[0] for c in contours])[-3]\n",
    "    contours_saved = []\n",
    "    for c in contours:\n",
    "    #draw the contour if it is not too small\n",
    "        if c.shape[0] > contouring_threshold: \n",
    "            #plt.plot(c[:, 1], c[:, 0], linewidth=2)\n",
    "            contours_saved.append(c)\n",
    "    return contours_saved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(img):\n",
    "    #resize photo so that only the hand is visible\n",
    "    # get the most left pixel that is not black\n",
    "    most_left = np.where(img.sum(axis=0) != 0)[0][0]\n",
    "    most_top = np.where(img.sum(axis=1) != 0)[0][0]\n",
    "    most_right = np.where(img.sum(axis=0) != 0)[0][-1]\n",
    "    most_bottom = np.where(img.sum(axis=1) != 0)[0][-1]\n",
    "    resized_img = img[most_top:most_bottom, most_left:most_right]\n",
    "    return resized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_hand_contours(img, longest_contours):\n",
    "    outline = np.zeros(img.shape)\n",
    "    for c in longest_contours:\n",
    "        #convert c to int\n",
    "        c = c.astype(int)\n",
    "        outline[c[:,0], c[:,1]] = 1\n",
    "    return outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_hand(img, contours):\n",
    "    #fill the hand with white\n",
    "    result = img.astype(np.uint8)\n",
    "    for c in contours:\n",
    "        rr, cc = polygon(c[:,0], c[:,1])\n",
    "        result[rr, cc] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_bright(img):\n",
    "    img = rgb2hsv(img)\n",
    "    v = img[:,:,2]\n",
    "    v = v*255\n",
    "    v = gaussian(v, sigma=1)\n",
    "    thresh = adaptive_thresholding(v)\n",
    "    print(thresh)\n",
    "    if thresh > 110:\n",
    "        print(\"bright\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"dark\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(img):\n",
    "    #feature is a 25x25 matrix each cell is the output birghtness of a 5x5 pixel in the image\n",
    "    b = np.zeros((42,42))\n",
    "    #we get the brightness of each cell by taking the average of the brightness of the pixels in the cell\n",
    "    for i in range(0,42):\n",
    "        for j in range(0,42):\n",
    "            b[i,j] = np.sum(img[i*3:(i+1)*3,j*3:(j+1)*3])\n",
    "    # print(b)\n",
    "    #show_images([b], ['feature'])\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_feature(b1, b2):\n",
    "    #compare the feature of two images\n",
    "    #if the two feature are black we consider them the same\n",
    "    #if the two feature are white have the same brightness we consider them the same\n",
    "    #if the two feature are white but have different brightness whithin a certain threshold we consider them the same\n",
    "    print(np.max(b1), np.min(b1))\n",
    "    print(np.max(b2), np.min(b2))\n",
    "    matches = 0\n",
    "    for i in range(0,42):\n",
    "        for j in range(0,42):\n",
    "            if (b1[i,j] == 0 and b2[i,j] == 0):\n",
    "                matches = matches + 1\n",
    "            # elif (b1[i,j] == b2[i,j]):\n",
    "            #     matches = matches + 1\n",
    "            elif (b1[i,j] > 0.2 and b2[i,j] > 0.2):\n",
    "                matches = matches + 1\n",
    "    print (matches)\n",
    "    print (matches/(42*42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img(img1):\n",
    "    #resize photo to 200x200\n",
    "    img_new = resize(img1, (256, 256), anti_aliasing=False)\n",
    "    return img_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing (img):\n",
    "    if(is_bright(img) == False):\n",
    "        img = rgb2gray(img)\n",
    "        img = img*255\n",
    "        filterd = gaussian(img, sigma=5)\n",
    "        best_threshold = adaptive_thresholding(filterd)\n",
    "        thresholded = filterd > best_threshold\n",
    "        result = thresholded\n",
    "        result = normalize_img(result)\n",
    "        result = resize_img(result)\n",
    "    else:\n",
    "        mask = skin_mask_rgb(img)\n",
    "        longest_contours = get_hand_contours(mask)\n",
    "        result = trace_hand_contours(mask, longest_contours)\n",
    "        result = fill_hand(result, longest_contours)\n",
    "        result = normalize_img(result)\n",
    "        result = resize_img(result)\n",
    "        \n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(image):\n",
    "    gx = np.zeros((image.shape[0], image.shape[1]))\n",
    "    gy = np.zeros((image.shape[0], image.shape[1]))\n",
    "    image = image.astype(np.float32)\n",
    "    gx[:, 1:-1] = (image[:, 2:] - image[:, :-2]) / 2\n",
    "    gy[1:-1, :] = (image[2:, :] - image[:-2, :]) / 2\n",
    "    \n",
    "    gx[:, 0] = image[:, 1] - image[:, 0]\n",
    "    gy[0, :] = image[1, :] - image[0, :]\n",
    "    \n",
    "    gx[:, -1] = image[:, -1] - image[:, -2]\n",
    "    gy[-1, :] = image[-1, :] - image[-2, :]\n",
    "    return gx, gy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hog_cell(orientations, magnitudes, n):\n",
    "    bin_size = int(180 / n)\n",
    "    hog = np.zeros(n)\n",
    "    for i in range(orientations.shape[0]):\n",
    "        for j in range(orientations.shape[1]):\n",
    "            angle = orientations[i, j]\n",
    "            magnitude = magnitudes[i, j]\n",
    "            bin = int(angle / bin_size)\n",
    "            if bin == n:\n",
    "                bin = n - 1\n",
    "            hog[bin] += magnitude\n",
    "            \n",
    "    return hog/(magnitudes.shape[0]*magnitudes.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_vector(v):\n",
    "    epsion = 1e-5\n",
    "    return v / np.sqrt(np.sum(v ** 2) + epsion ** 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hog_featrue(img):\n",
    "    gx, gy = compute_gradient(img)\n",
    "    x, y = gx.shape\n",
    "    cx , cy = 8, 8\n",
    "    bx , by = 1, 1\n",
    "    \n",
    "    magnitude = np.sqrt(gx**2 + gy**2)\n",
    "    angels = np.rad2deg(np.arctan2(gy, gx)) % 180\n",
    "    \n",
    "    n_cells_x = int(x / cx)\n",
    "    n_cells_y = int(y / cy)\n",
    "    n_blocks_x = n_cells_x - bx + 1\n",
    "    n_blocks_y = n_cells_y - by + 1\n",
    "    \n",
    "    cells = np.zeros((n_cells_x, n_cells_y, 9))\n",
    "    prev_x = 0\n",
    "    for i in range(n_cells_x):\n",
    "        prev_y = 0\n",
    "        for j in range(n_cells_y):\n",
    "            cells[i, j] = hog_cell(angels[prev_x:prev_x+cx, prev_y:prev_y+cy], magnitude[prev_x:prev_x+cx, prev_y:prev_y+cy], 9)\n",
    "            prev_y += cy\n",
    "        prev_x += cx\n",
    "    \n",
    "    cells_norm = np.zeros((n_blocks_x, n_blocks_y, 9))\n",
    "    #normalize the cells\n",
    "    \n",
    "    for i in range(n_blocks_x):\n",
    "        for j in range(n_blocks_y):\n",
    "            cells_norm[i, j] = normalize_vector(cells[i:i+bx, j:j+by].ravel())\n",
    "            \n",
    "    return cells_norm.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paper_hand_imgs():\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    #open folder with paper hands\n",
    "    #get all images in folder and append to imgs\n",
    "    path = 'C:/Users/Fastora/Downloads/HandGestureDetection/data/data/train/five/'\n",
    "    for filename in os.listdir(path):\n",
    "        img = io.imread(path+filename)\n",
    "        img = normalize_img(img)\n",
    "        resized = resize_img(img)\n",
    "        imgs.append(resized)\n",
    "        labels.append(\"paper\")\n",
    "    return imgs, labels\n",
    "\n",
    "def get_rad_hand_imgs():\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    #open folder with rock hands\n",
    "    #get all images in folder and append to imgs\n",
    "    path = 'C:/Users/Fastora/Downloads/HandGestureDetection/data/data/train/rad/'\n",
    "    for filename in os.listdir(path):\n",
    "        img = io.imread(path+filename)\n",
    "        img = normalize_img(img)\n",
    "        resized = resize_img(img)\n",
    "        imgs.append(resized)\n",
    "        #extract features hog\n",
    "        labels.append(\"rad\")\n",
    "    return imgs, labels\n",
    "\n",
    "def get_peace_hand_imgs():\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    #open folder with scissors hands\n",
    "    #get all images in folder and append to imgs\n",
    "    path = 'C:/Users/Fastora/Downloads/HandGestureDetection/data/data/train/peace/'\n",
    "    for filename in os.listdir(path):\n",
    "        img = io.imread(path+filename)\n",
    "        img = normalize_img(img)\n",
    "        resized = resize_img(img)\n",
    "        imgs.append(resized)\n",
    "        labels.append(\"peace\")\n",
    "    return imgs, labels\n",
    "\n",
    "def get_fist_hand_imgs():\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    #open folder with thumbs up hands\n",
    "    #get all images in folder and append to imgs\n",
    "    path = 'C:/Users/Fastora/Downloads/HandGestureDetection/data/data/train/fist/'\n",
    "    for filename in os.listdir(path):\n",
    "        img = io.imread(path+filename)\n",
    "        img = normalize_img(img)\n",
    "        resized = resize_img(img)\n",
    "        imgs.append(resized)\n",
    "        labels.append(\"fist\")\n",
    "    return imgs, labels\n",
    "\n",
    "def get_thumbsup_hand_imgs():\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    #open folder with thumbs up hands\n",
    "    #get all images in folder and append to imgs\n",
    "    path = 'C:/Users/Fastora/Downloads/HandGestureDetection/data/data/train/thumbsup/'\n",
    "    for filename in os.listdir(path):\n",
    "        img = io.imread(path+filename)\n",
    "        img = normalize_img(img)\n",
    "        resized = resize_img(img)\n",
    "        imgs.append(resized)\n",
    "        labels.append(\"thumbsup\")\n",
    "    return imgs, labels\n",
    "\n",
    "def get_perfecto_imgs():\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    #open folder with thumbs up hands\n",
    "    #get all images in folder and append to imgs\n",
    "    path = 'C:/Users/Fastora/Downloads/HandGestureDetection/data/data/train/perfecto/'\n",
    "    for filename in os.listdir(path):\n",
    "        img = io.imread(path+filename)\n",
    "        img = normalize_img(img)\n",
    "        resized = resize_img(img)\n",
    "        imgs.append(resized)\n",
    "        labels.append(\"perfecto\")\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(imgs_labels, feature_vector=True):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for img_label in imgs_labels:\n",
    "        #get hog features of image and append to features and label to labels\n",
    "        fd = get_hog_featrue(img_label[0])\n",
    "        labels.append(img_label[1])\n",
    "        features.append(fd)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_imgs , paper_labels = get_paper_hand_imgs()\n",
    "peace_imgs , peace_labels = get_peace_hand_imgs()\n",
    "fist_imgs , fist_labels = get_fist_hand_imgs()\n",
    "rad_imgs , rad_labels = get_rad_hand_imgs()\n",
    "thumbs_imgs , thumbs_labels = get_thumbsup_hand_imgs()\n",
    "perfecto_imgs , perfecto_labels = get_perfecto_imgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_labels = []\n",
    "for i in range(len(paper_imgs)):\n",
    "    imgs_labels.append((paper_imgs[i], paper_labels[i]))\n",
    "for i in range(len(fist_imgs)):\n",
    "    imgs_labels.append((fist_imgs[i], fist_labels[i]))\n",
    "for i in range(len(peace_imgs)):\n",
    "    imgs_labels.append((peace_imgs[i], peace_labels[i]))\n",
    "for i in range(len(rad_imgs)):\n",
    "    imgs_labels.append((rad_imgs[i], rad_labels[i]))\n",
    "for i in range(len(thumbs_imgs)):\n",
    "    imgs_labels.append((thumbs_imgs[i], thumbs_labels[i]))\n",
    "for i in range(len(perfecto_imgs)):\n",
    "    imgs_labels.append((perfecto_imgs[i], perfecto_labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features , labels = extract_features(imgs_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(clf, 'model.joblib')\n",
    "img = io.imread('hand41.jpg')\n",
    "r = pre_processing(img)\n",
    "show_images([r], ['hand'])\n",
    "hog_features = get_hog_featrue(r)\n",
    "print(clf.predict([hog_features]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f349190717d272d3ade161473407867587ac6304e8b0ec5270171486f6c34825"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

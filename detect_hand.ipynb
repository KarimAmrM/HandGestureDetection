{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from skimage import io\n",
    "from skimage.filters import median, gaussian\n",
    "import skimage.exposure as exposure\n",
    "from skimage.morphology import *\n",
    "from skimage.color import rgb2gray, rgb2hsv, rgb2yuv, rgb2ycbcr\n",
    "from skimage.measure import find_contours\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "import numpy as np\n",
    "from commonfunctions import *\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "from skimage.util import img_as_float\n",
    "from skimage.draw import polygon\n",
    "from sklearn import svm\n",
    "from joblib import dump, load\n",
    "import cv2\n",
    "import sys\n",
    "from time import sleep, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skin_mask_rgb(img):\n",
    "    red_channel = img[:,:,0]\n",
    "    green_channel = img[:,:,1]\n",
    "    blue_channel = img[:,:,2]\n",
    "    rgb_max = np.maximum(np.maximum(red_channel, green_channel), blue_channel)\n",
    "    rgb_min = np.minimum(np.minimum(red_channel, green_channel), blue_channel)\n",
    "    rgb_rule_1 = np.logical_and.reduce([\n",
    "        red_channel > 95, green_channel > 60, blue_channel > 60,\n",
    "        rgb_max - rgb_min > 15, abs(red_channel - green_channel) < 15,red_channel > green_channel, red_channel > blue_channel\n",
    "    ])\n",
    "    \n",
    "    rgb_rule_2 = np.logical_and.reduce([\n",
    "        red_channel > 220 , green_channel > 210 , blue_channel > 170,\n",
    "        abs(red_channel - green_channel) > 15, red_channel > blue_channel, green_channel > blue_channel\n",
    "    ])\n",
    "    return np.logical_or(rgb_rule_1, rgb_rule_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skin_mask_ycrcb(img):\n",
    "    result = np.zeros(img.shape)\n",
    "    for i in range(result.shape[0]):\n",
    "        for j in range(result.shape[1]):\n",
    "            y = 16 + (65.481 * result[i,j,0] + 128.553 * result[i,j,1] + 24.966 * result[i,j,2])\n",
    "            cg = 128 + (-81.085 * result[i,j,0] + 112 * result[i,j,1] - 30.915 * result[i,j,2])\n",
    "            cr = 128 + (112 * result[i,j,0] - 93.786 * result[i,j,1] - 18.214 * result[i,j,2])\n",
    "            if cg >=85 or cg <= 135:\n",
    "                cmp1 = -cg+260\n",
    "                cmp2 = -cg+280\n",
    "                if cr >= cmp1 and cr <= cmp2:\n",
    "                    result[i,j,0] = 255\n",
    "                    result[i,j,1] = 255\n",
    "                    result[i,j,2] = 255\n",
    "    show_images([result])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merged_mask(img):\n",
    "    ycbcr_mask = skin_mask_ycrcb(img)\n",
    "    hsv_mask = skin_mask_rgb(img)\n",
    "    rgb_mask = skin_mask_rgb(img)\n",
    "    r =  np.logical_and.reduce([ycbcr_mask, hsv_mask, rgb_mask])\n",
    "    return np.asarray(r, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hsv_mask(img):\n",
    "    h,s,v = rgb2hsv(img)[:,:,0], rgb2hsv(img)[:,:,1], rgb2hsv(img)[:,:,2]\n",
    "    h = np.rad2deg(h)\n",
    "    hsv_mask = np.logical_or(h < 50, h > 150)\n",
    "    return hsv_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_thresholding(img):\n",
    "    hist = exposure.histogram(img, nbins=256)\n",
    "    total_num_of_pixels = img.shape[0]*img.shape[1]\n",
    "    initial_threshold = round(sum(hist[1]*hist[0])/total_num_of_pixels)\n",
    "    grey_level_count = hist[1][-1]\n",
    "    while True:\n",
    "        list_of_lower_values = hist[1][hist[1] < initial_threshold]\n",
    "        frequency_of_lower_values = hist[0][hist[1] < initial_threshold]\n",
    "        lower_threshold = round(sum(list_of_lower_values*frequency_of_lower_values)/sum(frequency_of_lower_values))\n",
    "\n",
    "        list_of_higher_values = hist[1][hist[1] >= initial_threshold]\n",
    "        frequency_of_higher_values = hist[0][hist[1] >= initial_threshold]\n",
    "        upper_threshold = round(sum(list_of_higher_values*frequency_of_higher_values)/sum(frequency_of_higher_values))\n",
    "        new_threshold = round((lower_threshold + upper_threshold)/2)\n",
    "        \n",
    "        if new_threshold == initial_threshold:\n",
    "            break\n",
    "        else:\n",
    "            initial_threshold = new_threshold\n",
    "    return new_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hand_contours(hand_img):\n",
    "    #get the center of the hand\n",
    "    hand_img = hand_img.astype(np.uint8)\n",
    "    contours = find_contours(hand_img, 0.8, fully_connected='high')\n",
    "    contouring_threshold = 0\n",
    "    # get contoring threshold by finding the average length of the 3 largest contours\n",
    "    contouring_threshold  = np.mean(sorted([len(c) for c in contours])[-3:])\n",
    "    contours_saved = []\n",
    "    for c in contours:\n",
    "    #draw the contour if it is not too small\n",
    "        if c.shape[0] > contouring_threshold: \n",
    "            #plt.plot(c[:, 1], c[:, 0], linewidth=2)\n",
    "            contours_saved.append(c)\n",
    "    return contours_saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(img):\n",
    "    #resize photo so that only the hand is visible\n",
    "    # get the most left pixel that is not black\n",
    "    if img.shape[0] == 0 or img.shape[1] == 0:\n",
    "        return img\n",
    "    #check indcies are not out of bounds\n",
    "    most_left = np.where(img.sum(axis=0) != 0)[0][0]\n",
    "    most_top = np.where(img.sum(axis=1) != 0)[0][0]\n",
    "    most_right = np.where(img.sum(axis=0) != 0)[0][-1]\n",
    "    most_bottom = np.where(img.sum(axis=1) != 0)[0][-1]\n",
    "    resized_img = img[most_top:most_bottom, most_left:most_right]\n",
    "    return resized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_hand_contours(img, longest_contours):\n",
    "    outline = np.zeros(img.shape)\n",
    "    for c in longest_contours:\n",
    "        #convert c to int\n",
    "        c = c.astype(int)\n",
    "        outline[c[:,0], c[:,1]] = 1\n",
    "    return outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_hand(img, contours):\n",
    "    #fill the hand with white\n",
    "    result = img.astype(np.uint8)\n",
    "    for c in contours:\n",
    "        rr, cc = polygon(c[:,0], c[:,1])\n",
    "        result[rr, cc] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_bright(img):\n",
    "    img = rgb2hsv(img)\n",
    "    v = img[:,:,2]\n",
    "    v = v*255\n",
    "    v = gaussian(v, sigma=1)\n",
    "    thresh = adaptive_thresholding(v)\n",
    "    if thresh > 95:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img(img1):\n",
    "    #resize photo to 200x200\n",
    "    img_new = resize(img1, (256, 256), anti_aliasing=False)\n",
    "    return img_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing (img):\n",
    "    if(is_bright(img) == False):\n",
    "        img = rgb2gray(img)\n",
    "        img = img*255\n",
    "        filterd = gaussian(img, sigma=7)\n",
    "        #show_images([filterd])\n",
    "        best_threshold = adaptive_thresholding(filterd)\n",
    "        thresholded = filterd > best_threshold\n",
    "        #show_images([thresholded])\n",
    "        result = thresholded\n",
    "        result = normalize_img(result)\n",
    "        result = resize_img(result)\n",
    "    else:\n",
    "        mask = skin_mask_rgb(img)\n",
    "        longest_contours = get_hand_contours(mask)\n",
    "        result = trace_hand_contours(mask, longest_contours)\n",
    "        result = fill_hand(result, longest_contours)\n",
    "        result = normalize_img(result)\n",
    "        result = resize_img(result)\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_empty(img):\n",
    "    mask = skin_mask_rgb(img)\n",
    "    longest_contours = get_hand_contours(mask)\n",
    "    result = trace_hand_contours(mask, longest_contours)\n",
    "    result = fill_hand(result, longest_contours)\n",
    "    if result.sum() == 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(image):\n",
    "    gx = np.zeros((image.shape[0], image.shape[1]))\n",
    "    gy = np.zeros((image.shape[0], image.shape[1]))\n",
    "    image = image.astype(np.float32)\n",
    "    gx[:, 1:-1] = (image[:, 2:] - image[:, :-2]) / 2\n",
    "    gy[1:-1, :] = (image[2:, :] - image[:-2, :]) / 2\n",
    "    \n",
    "    gx[:, 0] = image[:, 1] - image[:, 0]\n",
    "    gy[0, :] = image[1, :] - image[0, :]\n",
    "    \n",
    "    gx[:, -1] = image[:, -1] - image[:, -2]\n",
    "    gy[-1, :] = image[-1, :] - image[-2, :]\n",
    "    return gx, gy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hog_cell(orientations, magnitudes, n):\n",
    "    bin_size = int(180 / n)\n",
    "    hog = np.zeros(n)\n",
    "    for i in range(orientations.shape[0]):\n",
    "        for j in range(orientations.shape[1]):\n",
    "            angle = orientations[i, j]\n",
    "            magnitude = magnitudes[i, j]\n",
    "            bin = int(angle / bin_size)\n",
    "            if bin == n:\n",
    "                bin = n - 1\n",
    "            hog[bin] += magnitude\n",
    "            \n",
    "    return hog/(magnitudes.shape[0]*magnitudes.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_vector(v):\n",
    "    epsion = 1e-5\n",
    "    return v / np.sqrt(np.sum(v ** 2) + epsion ** 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hog_featrue(img):\n",
    "    gx, gy = compute_gradient(img)\n",
    "    x, y = gx.shape\n",
    "    cx , cy = 8, 8\n",
    "    bx , by = 1, 1\n",
    "    \n",
    "    magnitude = np.sqrt(gx**2 + gy**2)\n",
    "    angels = np.rad2deg(np.arctan2(gy, gx)) % 180\n",
    "    \n",
    "    n_cells_x = int(x / cx)\n",
    "    n_cells_y = int(y / cy)\n",
    "    n_blocks_x = n_cells_x - bx + 1\n",
    "    n_blocks_y = n_cells_y - by + 1\n",
    "    \n",
    "    cells = np.zeros((n_cells_x, n_cells_y, 9))\n",
    "    prev_x = 0\n",
    "    for i in range(n_cells_x):\n",
    "        prev_y = 0\n",
    "        for j in range(n_cells_y):\n",
    "            cells[i, j] = hog_cell(angels[prev_x:prev_x+cx, prev_y:prev_y+cy], magnitude[prev_x:prev_x+cx, prev_y:prev_y+cy], 9)\n",
    "            prev_y += cy\n",
    "        prev_x += cx\n",
    "    \n",
    "    cells_norm = np.zeros((n_blocks_x, n_blocks_y, 9))\n",
    "    #normalize the cells\n",
    "    \n",
    "    for i in range(n_blocks_x):\n",
    "        for j in range(n_blocks_y):\n",
    "            cells_norm[i, j] = normalize_vector(cells[i:i+bx, j:j+by].ravel())\n",
    "            \n",
    "    return cells_norm.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = io.imread('images/hand7.jpg')\n",
    "if (is_empty(img)):\n",
    "    print(\"Empty\")\n",
    "r = pre_processing(img)\n",
    "show_images([img, r])\n",
    "#clf.predict([get_hog_featrue(r)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a video capture object\n",
    "clf = load('model.joblib')\n",
    "def flick(x):\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow('image')\n",
    "cv2.moveWindow('image',250,150)\n",
    "cv2.namedWindow('controls')\n",
    "cv2.moveWindow('controls',250,50)\n",
    "\n",
    "controls = np.zeros((50,750),np.uint8)\n",
    "cv2.putText(controls, \"W/w: Play, S/s: Stay, A/a: Prev, D/d: Next, E/e: Fast, Q/q: Slow, Esc: Exit\", (40,20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 255)\n",
    "\n",
    "video = 'movie.mp4'\n",
    "cap = cv2.VideoCapture(video)\n",
    "\n",
    "tots = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "i = 0\n",
    "cv2.createTrackbar('S','image', 0,int(tots)-1, flick)\n",
    "cv2.setTrackbarPos('S','image',0)\n",
    "\n",
    "cv2.createTrackbar('F','image', 1, 100, flick)\n",
    "frame_rate = 30\n",
    "cv2.setTrackbarPos('F','image',frame_rate)\n",
    "\n",
    "def process(im):\n",
    "    return cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "status = 'stay'\n",
    "vid = cv2.VideoCapture(0)\n",
    "c=0\n",
    "while(True):\n",
    "    c+=1\n",
    "    # Capture the video frame\n",
    "    #open video in full screen\n",
    "    vid.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)\n",
    "    ret, frame = vid.read()\n",
    "    roi=frame[100:500, 100:500]\n",
    "    cv2.rectangle(frame,(90,90),(500,500),(0,255,0),0)    \n",
    "    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    #take image from the rectangle \n",
    "    cv2.imshow('roi', roi)\n",
    "    #take a photo every 2 seconds and save it\n",
    "    #get current time \n",
    "    if c%30==0:\n",
    "        if (is_empty(roi) == False):\n",
    "            result=pre_processing(roi)\n",
    "            fd = get_hog_featrue(result)\n",
    "            print(clf.predict([fd]))\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    cv2.imshow(\"controls\",controls)\n",
    "\n",
    "    if i==tots-1:\n",
    "      i=0\n",
    "    cap.set(cv2.CAP_PROP_FRAME_COUNT, i)\n",
    "    ret, im = cap.read()\n",
    "    r = 750.0 / im.shape[1]\n",
    "    dim = (750, int(im.shape[0] * r))\n",
    "    im = cv2.resize(im, dim, interpolation = cv2.INTER_AREA)\n",
    "    if im.shape[0]>600:\n",
    "        im = cv2.resize(im, (500,500))\n",
    "        controls = cv2.resize(controls, (im.shape[1],25))\n",
    "    cv2.imshow('image', im)\n",
    "    status = { ord('s'):'stay', ord('S'):'stay',\n",
    "                ord('w'):'play', ord('W'):'play',\n",
    "                ord('a'):'prev_frame', ord('A'):'prev_frame',\n",
    "                ord('d'):'next_frame', ord('D'):'next_frame',\n",
    "                ord('q'):'slow', ord('Q'):'slow',\n",
    "                ord('e'):'fast', ord('E'):'fast',\n",
    "                ord('c'):'snap', ord('C'):'snap',\n",
    "                -1: status, \n",
    "                27: 'exit'}[cv2.waitKey(10)]\n",
    "    if status == 'play':\n",
    "        i = cv2.getTrackbarPos('S','image')\n",
    "        cap.set(cv2.CAP_PROP_FRAME_COUNT, i)\n",
    "        frame_rate = cv2.getTrackbarPos('F','image')\n",
    "        sleep((0.1-frame_rate/1000.0)**21021)\n",
    "        cap = cv2.VideoCapture(video)\n",
    "        #set the frame number to the current frame\n",
    "        #get the current frame number\n",
    "        i+=1\n",
    "        cv2.setTrackbarPos('S','image',i)\n",
    "        continue\n",
    "    if status == 'stay':\n",
    "      i = cv2.getTrackbarPos('S','image')\n",
    "      #freeze the frame and wait for the next command \n",
    "      # save current frame so we can play it again\n",
    "      cap = cv2.VideoCapture(video)\n",
    "      cap.set(cv2.CAP_PROP_FRAME_COUNT, i)\n",
    "      #save the frame\n",
    "      cv2.setTrackbarPos('S','image',i)\n",
    "    if status == 'exit':\n",
    "        break\n",
    "    if status=='prev_frame':\n",
    "        i-=1\n",
    "        cv2.setTrackbarPos('S','image',i)\n",
    "        status='stay'\n",
    "    if status=='next_frame':\n",
    "        i+=1\n",
    "        cv2.setTrackbarPos('S','image',i)\n",
    "        status='stay'\n",
    "    if status=='slow':\n",
    "        frame_rate = max(frame_rate - 5, 0)\n",
    "        cv2.setTrackbarPos('F', 'image', frame_rate)\n",
    "        status='play'\n",
    "    if status=='fast':\n",
    "        frame_rate = min(100,frame_rate+5)\n",
    "        cv2.setTrackbarPos('F', 'image', frame_rate)\n",
    "        status='play'\n",
    "    if status=='snap':\n",
    "        cv2.imwrite(\"./\"+\"Snap_\"+str(i)+\".jpg\",im)\n",
    "        print (\"Snap of Frame\",i,\"Taken!\")\n",
    "        status='stay'\n",
    "  \n",
    "# After the loop release the cap object\n",
    "vid.release()\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fist():\n",
    "    matches = 0\n",
    "    count = 0\n",
    "    path = 'C:/Users/Fastora/Downloads/HandGestureDetection/own/fist/'\n",
    "    for filename in os.listdir(path):\n",
    "        img = io.imread(path+filename)\n",
    "        img = pre_processing(img)\n",
    "        fd = get_hog_featrue(img)\n",
    "        #print(clf.predict([fd]))\n",
    "        if clf.predict([fd]) == ['fist']:\n",
    "            matches += 1\n",
    "        count += 1\n",
    "    print(matches)\n",
    "    print(count)\n",
    "    return matches,count\n",
    "\n",
    "def test_paper():\n",
    "    matches = 0\n",
    "    count = 0\n",
    "    path = 'C:/Users/Fastora/Downloads/HandGestureDetection/own/paper/'\n",
    "    for filename in os.listdir(path):\n",
    "        img = io.imread(path+filename)\n",
    "        img = pre_processing(img)\n",
    "        fd = get_hog_featrue(img)\n",
    "        #print(clf.predict([fd]))\n",
    "        if clf.predict([fd]) == ['paper']:\n",
    "            matches += 1\n",
    "        count += 1\n",
    "    print(matches)\n",
    "    print(count)\n",
    "    return matches,count\n",
    "\n",
    "def test_peace():\n",
    "    matches = 0\n",
    "    count = 0\n",
    "    path = 'C:/Users/Fastora/Downloads/HandGestureDetection/own/peace/'\n",
    "    for filename in os.listdir(path):\n",
    "        img = io.imread(path+filename)\n",
    "        img = pre_processing(img)\n",
    "        fd = get_hog_featrue(img)\n",
    "        #print(clf.predict([fd]))\n",
    "        if clf.predict([fd]) == ['peace']:\n",
    "            matches += 1\n",
    "        count += 1\n",
    "    return matches,count\n",
    "\n",
    "def test_perfecto():\n",
    "    matches = 0\n",
    "    count = 0\n",
    "    path = 'C:/Users/Fastora/Downloads/HandGestureDetection/own/perfecto/'\n",
    "    for filename in os.listdir(path):\n",
    "        img = io.imread(path+filename)\n",
    "        img = pre_processing(img)\n",
    "        fd = get_hog_featrue(img)\n",
    "        #print(clf.predict([fd]))\n",
    "        if clf.predict([fd]) == ['perfecto']:\n",
    "            matches += 1\n",
    "        count += 1\n",
    "    return matches,count\n",
    "\n",
    "def test_rad():\n",
    "    matches = 0\n",
    "    count = 0\n",
    "    path = 'C:/Users/Fastora/Downloads/HandGestureDetection/own/rad/'\n",
    "    for filename in os.listdir(path):\n",
    "        img = io.imread(path+filename)\n",
    "        img = pre_processing(img)\n",
    "        fd = get_hog_featrue(img)\n",
    "        #print(clf.predict([fd]))\n",
    "        if clf.predict([fd]) == ['rad']:\n",
    "            matches += 1\n",
    "        count += 1\n",
    "    return matches,count\n",
    "\n",
    "def test_thumbs():\n",
    "    matches = 0\n",
    "    count = 0\n",
    "    path = 'C:/Users/Fastora/Downloads/HandGestureDetection/own/thumbs/'\n",
    "    for filename in os.listdir(path):\n",
    "        img = io.imread(path+filename)\n",
    "        img = pre_processing(img)\n",
    "        fd = get_hog_featrue(img)\n",
    "        #print(clf.predict([fd]))\n",
    "        if clf.predict([fd]) == ['thumbs']:\n",
    "            matches += 1\n",
    "        count += 1\n",
    "    return matches,count\n",
    "\n",
    "def test_straigt():\n",
    "    matches = 0\n",
    "    count = 0\n",
    "    path = 'C:/Users/Fastora/Downloads/HandGestureDetection/own/straight/'\n",
    "    for filename in os.listdir(path):\n",
    "        img = io.imread(path+filename)\n",
    "        img = pre_processing(img)\n",
    "        fd = get_hog_featrue(img)\n",
    "        if clf.predict([fd]) == ['straight']:\n",
    "            matches += 1\n",
    "        count += 1\n",
    "    return matches,count\n",
    "\n",
    "def test_none():\n",
    "    matches = 0\n",
    "    count = 0\n",
    "    path = 'C:/Users/Fastora/Downloads/HandGestureDetection/own/none/'\n",
    "    for filename in os.listdir(path):\n",
    "        img = io.imread(path+filename)\n",
    "        if is_empty(img):\n",
    "            matches += 1\n",
    "        count += 1\n",
    "    return matches,count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tests():\n",
    "    fist_m, fist_c = test_fist()\n",
    "    paper_m, paper_c = test_paper()\n",
    "    peace_m, peace_c = test_peace()\n",
    "    perfecto_m , perfecto_c = test_perfecto()\n",
    "    rad_m, rad_c = test_rad()\n",
    "    thumbs_m, thumbs_c = test_thumbs()\n",
    "    straight_m , straight_c = test_straigt()\n",
    "    none_m, none_c = test_none()\n",
    "    print(\"Fist Accuracy: \",(fist_m/fist_c)*100)\n",
    "    print(\"Paper Accuracy: \",(paper_m/paper_c)*100)\n",
    "    print(\"Peace Accuracy: \",(peace_m/peace_c)*100)\n",
    "    print(\"Perfecto Accuracy: \",(perfecto_m/perfecto_c)*100)\n",
    "    print(\"Rad Accuracy: \",(rad_m/rad_c)*100)\n",
    "    print(\"Thumbs Accuracy: \",(thumbs_m/thumbs_c)*100)\n",
    "    print(\"Straight Accuracy: \",(straight_m/straight_c)*100)\n",
    "    print(\"None Accuracy: \",(none_m/none_c)*100)\n",
    "    print(\"Total Accuracy: \",((fist_m+paper_m+peace_m+perfecto_m+rad_m+thumbs_m+straight_m+none_m)/(fist_c+paper_c+peace_c+perfecto_c+rad_c+thumbs_c+straight_c+none_c))*100)    \n",
    "run_tests()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f349190717d272d3ade161473407867587ac6304e8b0ec5270171486f6c34825"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
